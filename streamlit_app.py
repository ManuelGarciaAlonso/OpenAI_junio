# streamlit_app.py (Versi贸n Final, Completa y Corregida)

import os
import streamlit as st
from rag import PDFChatbot
from streamlit_chat import message
from dotenv import load_dotenv
import time

# --- Carga de variables de entorno ---
load_dotenv()

# --- Constantes ---
APP_DIR = os.path.dirname(os.path.abspath(__file__))
PREPROCESSED_DATA_DIR = os.path.join(APP_DIR, "Processed_Texts", "preprocessed_markdown")
AVAILABLE_MODELS = ["o1-preview", "o1-mini", "gpt-4o", "gpt-4-turbo"]
DEFAULT_EMBEDDING_MODEL = "text-embedding-3-small"

st.set_page_config(page_title="ChatBot FS (OpenAI)", layout="wide")

# --- Inicializaci贸n b谩sica de la sesi贸n ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "pdf_chatbot" not in st.session_state:
    st.session_state.pdf_chatbot = None
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "gpt-4o"
if "last_retrieved_docs" not in st.session_state:
    st.session_state.last_retrieved_docs = []

# --- Configuraci贸n de la interfaz ---
st.title(" Asistente de Fundamentos del Software")

# --- Sidebar con controles ---
with st.sidebar:
    st.header("锔 Configuraci贸n")
    
    # Selector de modelo
    selected_model = st.selectbox(
        "Selecciona el modelo:",
        AVAILABLE_MODELS,
        index=AVAILABLE_MODELS.index(st.session_state.selected_model)
    )
    st.session_state.selected_model = selected_model
    
    # Bot贸n para inicializar/reiniciar chatbot
    if st.button(" Inicializar/Reiniciar Chatbot"):
        with st.spinner("Inicializando sistema..."):
            try:
                api_key = os.getenv("OPENAI_API_KEY")
                st.session_state.pdf_chatbot = PDFChatbot(
                    api_key=api_key,
                    chat_models=AVAILABLE_MODELS,
                    embedding_model=DEFAULT_EMBEDDING_MODEL
                )
                
                # Cargar datos si existen
                if os.path.exists(PREPROCESSED_DATA_DIR):
                    st.session_state.pdf_chatbot.load_existing_data(PREPROCESSED_DATA_DIR)
                
                st.success("隆Chatbot inicializado correctamente!")
            except Exception as e:
                st.error(f"Error al inicializar: {e}")
    
    # Ver temas disponibles
    if st.button(" Ver temas disponibles"):
        if st.session_state.pdf_chatbot:
            with st.spinner("Generando 铆ndice de temas..."):
                try:
                    # Usar el m茅todo real que existe en PDFChatbot
                    topics_info = st.session_state.pdf_chatbot.list_available_topics()
                    st.info(topics_info)
                except Exception as e:
                    st.error(f"Error al mostrar temas: {e}")

# --- rea de chat ---
# Mostrar mensajes existentes
for i, msg in enumerate(st.session_state.messages):
    if msg["role"] == "user":
        message(msg["content"], is_user=True, key=f"user_msg_{i}")
    else:
        message(msg["content"], is_user=False, key=f"ai_msg_{i}")

# Input del usuario
user_input = st.chat_input("Escribe tu pregunta aqu铆...")

# Procesar input cuando se env铆a
if user_input:
    # A帽adir mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # Verificar si el chatbot est谩 inicializado
    if not st.session_state.pdf_chatbot:
        st.error("Por favor, inicializa el chatbot primero usando el bot贸n en la barra lateral.")
        st.session_state.messages.append({"role": "assistant", "content": "锔 Por favor, inicializa el chatbot primero usando el bot贸n en la barra lateral."})
    else:
        # Procesar la consulta
        with st.spinner("Procesando tu consulta..."):
            try:
                # La funci贸n devuelve (response, retrieved_docs)
                response_data = st.session_state.pdf_chatbot.answer_question(
                    user_input, 
                    model_name=st.session_state.selected_model
                )
                
                # Extraer respuesta y documentos de manera m谩s robusta
                if isinstance(response_data, tuple) and len(response_data) >= 1:
                    response_text = response_data[0]
                    retrieved_docs = response_data[1] if len(response_data) > 1 else []
                else:
                    response_text = response_data  # En caso de que solo devuelva texto
                    retrieved_docs = []
                
                # Guardar documentos recuperados para posible uso futuro
                st.session_state.last_retrieved_docs = retrieved_docs
                
                # A帽adir respuesta al historial
                st.session_state.messages.append({"role": "assistant", "content": response_text})
            except Exception as e:
                error_msg = f"Error al procesar tu consulta: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": f"锔 {error_msg}"})
    
    # Recargar para mostrar la nueva respuesta
    st.rerun()